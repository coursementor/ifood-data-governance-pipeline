# Ifood Data Governance Pipeline: Quality, Traceability, Security, Compliance Dashboard Insights

[![Releases](https://img.shields.io/badge/Releases-See%20All-blue?logo=github&logoColor=white)](https://github.com/coursementor/ifood-data-governance-pipeline/releases)

Acesse as releases em https://github.com/coursementor/ifood-data-governance-pipeline/releases

Vis√£o geral
- Este reposit√≥rio mostra uma solu√ß√£o completa de governan√ßa de dados com foco em qualidade, rastreabilidade, seguran√ßa e conformidade com LGPD. O ecossistema integra ferramentas modernas para entregar um painel de governan√ßa de dados interativo e √∫til no dia a dia das equipes de dados.
- O objetivo √© oferecer um conjunto de componentes que funcionam bem juntos, mas que tamb√©m podem ser usados separadamente. Cada pe√ßa foi pensada para ser simples de entender, configurar e estender.

Objetivos e valor
- Garantir qualidade de dados: valida√ß√£o, limpeza, checagem de consist√™ncia e observabilidade.
- Rastreabilidade completa: origem dos dados, transforma√ß√µes aplicadas, depend√™ncias entre fontes e consumo.
- Seguran√ßa e conformidade: controles de acesso, auditoria, masking de dados sens√≠veis e conformidade com LGPD.
- Ecossistema interativo: dashboards em tempo real, relat√≥rios ad hoc, alertas e observabilidade centralizada.
- Ado√ß√£o gradual: etapas bem definidas para come√ßar com o essencial e evoluir para capacidades avan√ßadas.

Arquitetura de alto n√≠vel
- Orquestra√ß√£o de dados com Airflow: gerencia pipelines, DAGs e tarefas, com logs centralizados.
- Transforma√ß√µes com dbt: modelo de dados, testes de qualidade e documenta√ß√£o integrada.
- Valida√ß√£o com Pydantic: contratos de dados, valida√ß√£o de entrada/sa√≠da e mensagens de erro claras.
- Dashboards com Streamlit: interface para governan√ßa, monitoramento de qualidade, m√©tricas e explora√ß√£o de dados.
- Visualiza√ß√£o de dados: bibliotecas como Matplotlib, Seaborn e Pandas para gr√°ficos integrados aos fluxos de dados.
- Armazenamento e cache: bancos de dados relacionais para metadados, Redis para cache r√°pido e PySpark para processamento em grande escala.
- Cat√°logo e rastreabilidade: cat√°logo de dados com linhagem, metadados de fontes, transforma√ß√µes e consumo.
- Observabilidade: logs estruturados, m√©tricas, celularidade de dashboards e alertas de anomalias.
- Seguran√ßa: controle de acesso baseado em pap√©is, registros de auditoria e conformidade com LGPD.

Arquitetura detalhada (componentes)
- Airflow: orquestra DAGs, agenda tarefas, gerencia depend√™ncias e retries. Logs ficam dispon√≠veis no UI do Airflow e em reposit√≥rios de logs para auditoria.
- dbt: gerencia transforma√ß√µes de dados, testes de qualidade, documenta√ß√£o auto gerada e lineage entre modelos. Os modelos de dbt alimentam o data mart utilizado pelos dashboards.
- Streamlit: camada de apresenta√ß√£o que exp√µe dashboards, pain√©is de qualidade, auditoria e m√©tricas. Conecta aos modelos de dados e aos resultados de transforma√ß√µes.
- Pydantic: valida contratos de dados entre fontes, valida schemas de entrada e sa√≠da, facilita mensagens de erro padronizadas.
- PySpark: processamento em grande escala, especialmente √∫til para conjuntos de dados volumosos ou opera√ß√µes de transforma√ß√£o que exigem paralelismo.
- Pandas, NumPy, Matplotlib, Seaborn: bibliotecas para an√°lise, manipula√ß√£o, estat√≠sticas e visualiza√ß√£o de dados dentro dos notebooks, scripts de ETL ou componentes do Streamlit.
- Redis: cache para melhorar resposta de dashboards, sess√µes de usu√°rio e resultados de consultas repetidas.
- Dados e seguran√ßa: camadas de criptografia, masking, controle de acesso, pol√≠ticas de LGPD aplicadas a dados sens√≠veis.

Tecnologias e stack
- Orquestra√ß√£o: Apache Airflow
- Transforma√ß√£o de dados: dbt
- Interface e visualiza√ß√£o: Streamlit, Matplotlib, Seaborn
- Valida√ß√£o de dados: Pydantic
- Processamento de dados: PySpark
- Almacenamento e metadados: bancos de dados relacionais, data catalog, Redis
- Observabilidade: logs estruturados, m√©tricas, alertas
- Linguagens: Python, SQL
- Padr√µes de dados: contratos de dados, schemas, valida√ß√£o de entrada/sa√≠da
- Conformidade: LGPD, governan√ßa de dados sens√≠veis, auditoria

Guia r√°pido de uso
- Objetivo r√°pido: ter uma vis√£o consolidada da qualidade de dados, rastreabilidade e conformidade, com dashboards interativos.
- Premissa: um conjunto m√≠nimo de pipelines j√° integrada, com dados simulados para demonstra√ß√£o.

Guia r√°pido de configura√ß√£o (sem Docker)
- Pr√©-requisitos
  - Python 3.9 ou superior
  - pip atualizado
- Passo a passo
  - clone o reposit√≥rio: git clone https://github.com/coursementor/ifood-data-governance-pipeline.git
  - crie um ambiente isolado: python -m venv venv && source venv/bin/activate
  - instale depend√™ncias: pip install -r requirements.txt
  - configure vari√°veis de ambiente b√°sicas (exemplos):

    - LGPD_ENABLED=true
    - DATA_LAKE_URL=postgresql://usuario:senha@localhost:5432/bancodados
    - DBT_PROFILE=default
    - AIRFLOW__CORE__EXECUTOR=LocalExecutor

  - inicie os servi√ßos
    - Airflow: export AIRFLOW_HOME=$(pwd)/airflow && airflow db init && airflow scheduler & airflow webserver -p 8080
    - Streamlit: streamlit run apps/gov_dashboard.py --server.port 8501
  - acesse os dashboards
    - Airflow UI: http://localhost:8080
    - Streamlit UI: http://localhost:8501

Guia r√°pido de configura√ß√£o com Docker
- Docker facilita a configura√ß√£o e o isolamento de depend√™ncias.
- Requisitos
  - Docker e Docker Compose instalados
- Passos
  - abra o terminal no diret√≥rio do projeto
  - execute: docker-compose up --build -d
  - abra: http://localhost:8080 para Airflow; http://localhost:8501 para Streamlit
- Observa√ß√£o
  - a imagem docker do projeto j√° cont√©m vers√µes espec√≠ficas de Airflow, dbt e Streamlit para evitar conflitos de depend√™ncias.

Como funciona a governan√ßa de dados neste projeto
- Qualidade de dados
  - valida√ß√£o de dados na entrada com Pydantic
  - testes de qualidade com dbt
  - dashboards que mostram m√©tricas de qualidade: taxa de preenchimento, duplicidade, conformidade com regras de neg√≥cio
- Rastreamento e linhagem
  - cat√°logos de dados que registram fonte, transforma√ß√µes, depend√™ncias
  - visualiza√ß√µes de linhagem que ajudam a entender como um dado percorre o pipeline
- Seguran√ßa e LGPD
  - controle de acesso em n√≠vel de usu√°rio e pap√©is
  - masking de dados sens√≠veis nos ambientes de desenvolvimento
  - rastreabilidade de quem acessou quais dados
  - auditoria de atividades e mudan√ßas no pipeline
- Observabilidade
  - logs centralizados, m√©tricas exportadas para dashboards
  - alertas para falhas de pipelines, quedas de qualidade de dados
- Observabilidade de desempenho
  - tempo de execu√ß√£o de tarefas, uso de recursos, gargalos de transforma√ß√£o

Fluxos de dados e pipelines
- Fluxo de ingest√£o
  - fontes de dados s√£o conectadas por conectores; valida√ß√£o inicial acontece na camada de entrada
  - dados brutos s√£o armazenados em uma √°rea de landing com logs de ingest√£o
- Transforma√ß√£o e modelagem
  - dbt orquestra modelos de dados, aplica transforma√ß√µes, valida com testes e gera documenta√ß√£o
  - modelos alimentam o data mart para dashboards
- Valida√ß√£o cont√≠nua
  - contratos de dados com Pydantic garantem que mensagens entre etapas estejam corretas
  - testes automatizados asseguram que mudan√ßas n√£o quebrem expectativas
- Visualiza√ß√£o e governan√ßa
  - Streamlit oferece dashboards com m√©tricas de qualidade, trabalho de linha de dados, conformidade com LGPD
  - os usu√°rios podem explorar dados, ver a proveni√™ncia e entender as regras aplicadas

Como usar os recursos para governan√ßa pr√°tica
- Painel de governan√ßa
  - apresenta m√©tricas de qualidade, status de pipelines, mensagens de viola√ß√£o de regras
  - permite explorar datasets, ver cadastro de dados, e entender a origem
- Auditoria
  - logs de execu√ß√£o de DAGs e transforma√ß√µes
  - disponibilidade de m√©tricas de auditoria para auditorias internas ou externas
- Gerenciamento de conformidade LGPD
  - pol√≠ticas para dados sens√≠veis, mascaramento de dados em ambientes n√£o seguros
  - controles de acesso para reduzir exibi√ß√£o de dados sens√≠veis a usu√°rios autorizados
- Observabilidade de pipeline
  - rastreabilidade de falhas, rerun de tarefas com justificativas
  - dashboards de desempenho ajudam equipes a identificar gargalos

Cataloga√ß√£o de dados e linhagem
- Cat√°logo de dados
  - cada fonte de dados tem metadados, propriet√°rios, frequ√™ncia de atualiza√ß√£o e qualidade esperada
  - os modelos de dbt t√™m documenta√ß√£o integrada que aparece no cat√°logo
- Linhagem de dados
  - registra de onde v√™m os dados, para onde v√£o, e as transforma√ß√µes aplicadas
  - facilita auditorias, regress√µes e impacto de mudan√ßas

Qualidade de dados em profundidade
- Regras e valida√ß√µes
  - regras definidas para formatos, range de valores, unicidade, integridade referencial
  - valida√ß√£o de esquemas com Pydantic para mensagens entre servi√ßos
- Testes de qualidade com dbt
  - testes de unicidade, n√£o nulos, relacionamentos entre tabelas
  - documenta√ß√£o autom√°tica dos modelos
- Visualiza√ß√£o de qualidade
  - gr√°ficos que mostram evolu√ß√£o de m√©tricas de qualidade ao longo do tempo
  - alertas quando valores saem do esperado

Observabilidade e monitoramento
- Logs estruturados
  - padroniza√ß√£o de mensagens para facilitar buscas
- M√©tricas
  - tempo de execu√ß√£o, taxa de sucesso, taxa de falha, taxa de dados ausentes
- Alertas
  - notifica√ß√µes para falhas cr√≠ticas, degrada√ß√£o de qualidade de dados
- Dashboards
  - pain√©is que integram v√°rias fontes de dados e apresentam uma vis√£o unificada

Seguran√ßa, LGPD e conformidade
- Princ√≠pios-chave
  - least privilege (menor privil√©gio)
  - minimiza√ß√£o de dados
  - accountability (responsabiliza√ß√£o)
  - rastreabilidade de acessos e opera√ß√µes
- Pr√°ticas implementadas
  - mascaramento de dados sens√≠veis em ambientes de desenvolvimento
  - logs de auditoria para altera√ß√µes de dados e acessos
  - pol√≠ticas de reten√ß√£o e descarte seguro de dados
- Educa√ß√£o e governan√ßa
  - treinamentos simples para equipes de dados sobre LGPD e pr√°ticas de governan√ßa
  - documenta√ß√£o clara das regras e pol√≠ticas adotadas

Pydantic e contratos de dados
- Contratos expl√≠citos
  - modelos Pydantic definem como as mensagens devem ser estruturadas
  - ajudam a detectar erros de compatibilidade entre servi√ßos cedo
- Valida√ß√£o cont√≠nua
  - valida√ß√µes ocorrem durante ingest√£o, transforma√ß√£o e exporta√ß√£o
  - mensagens de erro padronizadas facilitam a corre√ß√£o r√°pida

Processo de desenvolvimento, testes e qualidade
- Organiza√ß√£o do c√≥digo
  - m√≥dulos claros para ingest√£o, transforma√ß√£o, valida√ß√£o, visualiza√ß√£o e utilit√°rios
  - padr√µes simples para facilitar a manuten√ß√£o
- Testes
  - testes unit√°rios com pytest para valida√ß√£o de fun√ß√µes, modelos e contratos
  - testes de integra√ß√£o para fluxos entre Airflow, dbt e Streamlit
  - valida√ß√µes de dados em pipelines com casos de teste simulados
- Verifica√ß√µes de qualidade de c√≥digo
  - linting, formata√ß√£o e checagens est√°ticas para manter a qualidade do c√≥digo
- CI/CD
  - pipelines de CI que executam lint, testes e valida√ß√£o de schemas
  - pipelines de CD para implanta√ß√µes seguras de ambientes de produ√ß√£o
  - automa√ß√£o para publicar novas vers√µes no reposit√≥rio de releases

Guia de contribui√ß√£o
- Como contribuir
  - criar uma feature branch: git checkout -b feature/nova-funca
  - desenvolver a feature com testes
  - abrir um PR descrevendo a motiva√ß√£o, impactos esperados e como testar
- Regras de estilo
  - c√≥digo limpo, nomes descritivos, fun√ß√µes curtas
  - documenta√ß√£o de novas APIs ou mudan√ßas de contrato com Pydantic
- Testes
  - incluir casos de borda, dados sens√≠veis e cen√°rios de LGPD
  - manter a cobertura de testes alta
- Revis√µes
  - pares revisam PRs para qualidade, seguran√ßa e conformidade
  - feedback r√°pido evita gargalos de entrega

Arquitetura de dados e modelos
- Modelagem
  - esquemas para fontes, transforma√ß√µes, m√©tricas e dashboards
  - contratos de dados definem formatos, tipos e regras de valida√ß√£o
- Dados sens√≠veis
  - segmentos com dados sens√≠veis marcados
  - pol√≠ticas de masking aplicadas conforme o ambiente
- Linhagem
  - a cada etapa do pipeline, a linhagem √© atualizada
  - facilita auditorias, mudan√ßas e troubleshoot

Exemplos de uso e casos de neg√≥cio
- Cen√°rio de qualidade de dados
  - analista verifica m√©tricas de qualidade no dashboard
  - se valores inconsistentes s√£o detectados, a tarefa de corre√ß√£o √© acionada
- Cen√°rio de conformidade
  - dados sens√≠veis s√£o mascarados em ambientes de desenvolvimento
  - logs de acesso s√£o audit√°veis para inspe√ß√£o
- Cen√°rio de rastreabilidade
  - um dataset pode ser rastreado desde a fonte at√© o consumidor final
  - mudan√ßas em qualquer etapa aparecem no hist√≥rico de linhagem

Estrutura de pastas, conven√ß√µes e organiza√ß√£o do reposit√≥rio
- Diret√≥rios comuns
  - dags/ ou airflow/ para DAGs do Airflow
  - models/ para modelos dbt
  - pipelines/ para scripts de ETL/ELT
  - apps/ ou dashboards/ para Streamlit
  - tests/ para testes automatizados
  - notebooks/ para explora√ß√£o de dados
  - config/ para configura√ß√µes e vari√°veis de ambiente
- Conven√ß√µes de nomes
  - nomes descritivos para pipelines, modelos e fun√ß√µes
  - vers√µes expl√≠citas para depend√™ncias e contratos
- Documenta√ß√£o
  - docs/ com guias, perguntas frequentes e arquiteturas
  - documenta√ß√£o inline nos m√≥dulos com docstrings
- Dados de exemplo
  - datasets simulados para demonstra√ß√£o, sem dados reais

Como verificar a vers√£o mais recente
- O link de releases cont√©m as vers√µes mais recentes da solu√ß√£o e assets para download. Use o seguinte link para explorar as vers√µes dispon√≠veis: https://github.com/coursementor/ifood-data-governance-pipeline/releases
- Observa√ß√£o: se o link contiver uma parte de caminho, baixe o arquivo de release correspondente e execute os scripts ou instale o conte√∫do conforme descrito na documenta√ß√£o do release.

Licen√ßa
- Este projeto utiliza uma licen√ßa aberta para facilitar uso, modifica√ß√£o e compartilhamento. (Se preferir, substitua pelo tipo de licen√ßa exato adotado.)

Notas sobre licen√ßas e uso de componentes
- Alguns componentes podem ter licen√ßas espec√≠ficas. Siga as regras de uso de cada biblioteca (Streamlit, Airflow, dbt, Pydantic, Pandas, etc.) e cite cr√©ditos quando necess√°rio.
- Em ambientes reais, esteja atento √†s pol√≠ticas de LGPD para dados reais. Teste com dados sint√©ticos para evitar qualquer exposi√ß√£o acidental de informa√ß√µes sens√≠veis.

Diagrama de arquitetura (visuais)
- O diagrama de arquitetura mostra a integra√ß√£o entre Airflow, dbt, Pydantic, Streamlit, PySpark, Pandas e Redis.
- Este diagrama pode ser encontrado na documenta√ß√£o oficial do projeto ou em assets da se√ß√£o de arquitetura. Voc√™ pode visualizar a arquitetura atrav√©s de imagens anexadas no reposit√≥rio ou diagramas no formato SVG/PNG inclu√≠dos no diret√≥rio docs/arquitetura.

Perguntas frequentes
- O que √© necess√°rio para iniciar?
  - Um ambiente com Python 3.9+, depend√™ncias instaladas, e acessos b√°sicos aos componentes (Airflow, Streamlit).
- Como testar a integra√ß√£o entre componentes?
  - Execute um pipeline simples com ingest√£o, transforma√ß√£o e visualiza√ß√£o de resultados. Verifique logs, dashboards e a consist√™ncia de dados.
- Posso usar apenas partes do sistema?
  - Sim. Este ecossistema foi desenhado para modularidade. A parte de governan√ßa pode ser usada independentemente, assim como a camada de visualiza√ß√£o.

Contribui√ß√£o de qualidade de dados e LGPD
- Contribu√≠mos com controles que ajudam a manter a qualidade de dados e conformidade com LGPD.
- O objetivo √© que equipes possam adotar as pr√°ticas de governan√ßa sem complica√ß√µes, mantendo a privacidade e a seguran√ßa.
- Incentivamos a ado√ß√£o de pr√°ticas de dados √©ticas e respeitosas.
- Em caso de d√∫vidas, procure a equipe de governan√ßa de dados para orienta√ß√£o.

Guia de configura√ß√£o avan√ßada
- Configura√ß√£o de ambiente isolado
  - use um ambiente virtual com isola√ß√£o total para evitar conflitos com outras bibliotecas
  - gerencie pacotes com ferramentas como pipenv ou poetry para controle de depend√™ncias
- Configura√ß√£o de armazenamento
  - configure o data lake/warehouse conforme as pol√≠ticas da organiza√ß√£o
  - assegure que as credenciais estejam protegidas, usando vari√°veis de ambiente e servi√ßos de segredo
- Configura√ß√£o de seguran√ßa
  - aplique pol√≠ticas de acesso com base em pap√©is
  - mantenha logs de auditoria e mecanismos de monitoramento ativos
- Configura√ß√£o de LGPD
  - defina regras de masking para dados sens√≠veis
  - registre atividades de acesso e altera√ß√µes em dados sens√≠veis
  - documente as pol√≠ticas e as exce√ß√µes em um local de f√°cil consulta

Notas finais sobre implanta√ß√£o e manuten√ß√£o
- Este √© um ecossistema vivo. Provedores de dados, equipes de seguran√ßa e equipes de produto podem precisar ajustar as pol√≠ticas, as regras e as visualiza√ß√µes ao longo do tempo.
- Mantenha a documenta√ß√£o atualizada, incluindo guias de usu√°rio, guias de administrador e notas de vers√£o.
- Planeje ciclos regulares de revis√£o de pol√≠ticas de LGPD, padr√µes de dados e planos de resposta a incidentes.

Recursos adicionais
- Documenta√ß√£o externa para as tecnologias utilizadas
  - Airflow: guias de DAGs, operadores, sensores e melhores pr√°ticas
  - dbt: modelo, testes, documenta√ß√£o e linhagem
  - Pydantic: schemas, valida√ß√£o e contratos de dados
  - Streamlit: constru√ß√£o de dashboards, intera√ß√µes, componentes
  - Pandas, NumPy, Matplotlib, Seaborn: manipula√ß√£o, estat√≠stica e visualiza√ß√£o de dados
  - Redis: cache, sess√µes
  - PySpark: processamento distribu√≠do
- Pr√°ticas de governan√ßa de dados
  - pol√≠ticas de qualidade, seguran√ßa de dados, rastreabilidade e compliance

Releases
- Para baixar a vers√£o mais recente ou verificar novas atualiza√ß√µes, visite a p√°gina de releases em https://github.com/coursementor/ifood-data-governance-pipeline/releases. Em casos de download, baixe o arquivo de release correspondente e execute o conte√∫do conforme descrito na documenta√ß√£o do release.
- O arquivo correspondente pode estar dispon√≠vel na se√ß√£o de releases; se houver, siga as instru√ß√µes para baixar, extrair e executar os componentes do release. Voltando ao in√≠cio, acesse novamente o link para valida√ß√£o r√°pida: https://github.com/coursementor/ifood-data-governance-pipeline/releases

Observabilidade de dados
- Este projeto enfatiza observabilidade para que equipes de dados possam entender rapidamente o estado dos pipelines e a qualidade dos dados.
- A cobertura de observabilidade inclui logs, m√©tricas, alerta de falhas e contexto para diagn√≥stico.

Compatibilidade e extens√µes futuras
- A arquitetura √© pensada para evoluir. Futuras expans√µes podem incluir:
  - Integra√ß√£o com novas fontes de dados
  - Suporte a mais modelos de dados e formatos de arquivo
  - Capacidades adicionais de LGPD, incluindo controles de consentimento e gest√£o de dados sens√≠veis
  - Melhorias de UI/UX para dashboards e dashboards interativos
- A comunidade de usu√°rios pode propor melhorias atrav√©s de pull requests, issues e discuss√µes.

Licen√ßa (reiterado)
- Licen√ßa: MIT (ou conforme definido pela equipe). Use conforme as pol√≠ticas da organiza√ß√£o e respeite todas as depend√™ncias de terceiros.

Recursos visuais
- Imagens de exemplo podem ser incorporadas para ilustrar fluxos de dados, m√©tricas de qualidade e arquitetura.
- Emojis podem ser usados para tornar o README mais acess√≠vel, por exemplo: üß≠ para orienta√ß√£o de fluxo, üîí para seguran√ßa, üìä para dashboards, üß™ para testes, üö¶ para estados de pipeline.

Notas finais
- Este reposit√≥rio busca demonstrar uma solu√ß√£o pr√°tica para governan√ßa de dados, com foco em usabilidade, qualidade, rastreabilidade, seguran√ßa e conformidade com LGPD.
- A equipe convida contribui√ß√µes que melhorem a clareza, a seguran√ßa, o desempenho e a cobertura de governan√ßa de dados.

Observa√ß√µes de uso do link de releases (revisado)
- O link de releases cont√©m a vers√£o mais recente e ativos para download. Use o link no in√≠cio para acessar as vers√µes: https://github.com/coursementor/ifood-data-governance-pipeline/releases
- Se houver um arquivo espec√≠fico dentro do release, baixe-o e execute os scripts ou siga as instru√ß√µes de instala√ß√£o que acompanham o release.
- Voc√™ tamb√©m pode visitar a p√°gina de releases a qualquer momento para confirmar a disponibilidade de novas vers√µes e atualiza√ß√µes de componentes do ecossistema.

Fica claro que este projeto √© mais do que uma cole√ß√£o de scripts. Ele consolida pr√°ticas s√≥lidas de governan√ßa de dados, oferece um caminho claro para equipes de dados adotarem conceitos de qualidade, rastreabilidade, seguran√ßa e conformidade, tudo acompanhado por um conjunto de dashboards interativos. O objetivo √© tornar a governan√ßa tang√≠vel e acess√≠vel, para que decis√µes fiquem mais r√°pidas, seguras e bem fundamentadas.